# Mitrailleuse

> **Multiâ€‘provider AI request launcher & batchâ€‘runner** supporting **OpenAI**, **DeepSeek**, and **DeepL**, with a gRPC faÃ§ade, Dockerised runtime, and samplingâ€‘aware task folders.

> Mitrailleuse is an extensible microâ€‘service that orchestrates highâ€‘throughput requests to multiple generativeâ€‘AI providers (OpenAI, DeepSeek, DeepL) while providing a consistent gRPC interface, pluggable adapters, dynamic prompt mapping, and firstâ€‘class batch support.
---

## âœ¨ Key features

| Capability            | Details                                                                                                                     |
| --------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| ğŸ—‚ï¸ Task folders      | Every call lives under `tasks/<user_id>/<api>_<task>_<timestamp>/` (inputs, outputs, logs, config).                         |
| ğŸ“¡ Multiâ€‘provider     | Switch between `openai`, `deepseek`, `deepl` by setting `api` in the task JSON or `--api` on the CLI.                       |
| ğŸš€ gRPC service       | Exposes `CreateTask`, `SendSingle`, `CreateBatch`, `CheckBatchStatus`, `DownloadBatchResults`. Reflection & health enabled. |
| ğŸ³ Dockerâ€‘ready       | Single `mitrailleuse-grpc` image builds from `Dockerfile`, spun up via `dockerâ€‘compose`.                                    |
| ğŸ” Sampling           | `config.general.sampling` lets you process the first *N* lines for quick dryâ€‘runs.                                          |
| ğŸ§© Adapters           | New providers drop in via `Adapters` registry with `send_single` / `send_batch`.                                            |
| ğŸ“œ CLI Interface      | New command-line interface for task management and execution.                                                               |
| ğŸ”„ File Flattening    | Automatic flattening of nested JSON structures for consistent processing.                                                   |
| ğŸ” Similarity Check   | Configurable similarity checking to prevent duplicate responses.                                                            |
| ğŸ’¾ Caching            | In-memory and file-based caching for improved performance.                                                                  |

---

## ğŸ—ï¸ Architecture
```
           +------------------------------+
           |           Clients            |
           |  (Postman, grpcurl, CLI)     |
           +------------------------------+
                        â”‚ gRPC
                        â–¼
           +------------------------------+
           |  Mitrailleuse gRPC Server    |
           |  â€¢ Health + Reflection       |
           |  â€¢ RequestService            |
           +-------------â”¬----------------+
                         â”‚ chooses adapter
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                             â”‚
+------------------+         +------------------+
|  OpenAIAdapter   |         | DeepSeekAdapter  |
|  â€“ batch + chat  |         |  â€“ chat          |
+------------------+         +------------------+
           â”‚                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
               +------------------+
               |  DeepLAdapter    |
               |  â€“ translate     |
               +------------------+
```

## Quick start

### Prerequisites

* Python 3.12+
* Docker 24.x (optional but recommended)
* Provider API keys in config.json

### 1 Â· Clone & build

```bash
# clone
git clone https://github.com/theFellandes/mitrailleuse.git
cd mitrailleuse

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install package in development mode
pip install -e .

# Install dependencies
pip install -r requirements.txt

# Generate gRPC stubs
python -m grpc_tools.protoc -I. \
  --python_out=. --grpc_python_out=. mitrailleuse/proto/mitrailleuse.proto

# build the gRPC server image (if using Docker)
docker compose build mitrailleuse-grpc
```

### 2 Â· Set API keys

Create `.env` in the repo root:

```dotenv
OPENAI_API_KEY=skâ€‘...
DEEPSEEK_API_KEY=dskâ€‘...
DEEPL_API_KEY=dpaâ€‘...
```

### 3 Â· Run the stack

#### Option 1: Run directly with Python
```bash
# Start the gRPC server
python -m mitrailleuse.infrastructure.grpc.server
```

#### Option 2: Run with Docker
```bash
docker compose up -d mitrailleuse-grpc
```

The server listens on **`localhost:50051`** (gRPC, plaintext).

### 4 Â· Smoke test

```bash
grpcurl -plaintext localhost:50051 list
```

Should list `mitrailleuse.MitrailleuseService`.

---

## ğŸ”§ Configuration files

### `config.json` template

```jsonc
{
  "general": {
    "verbose": true,
    "sampling": { "enable_sampling": true, "sample_size": 100 },
    "check_similarity": true,
    "similarity_settings": {
      "similarity_threshold": 0.8,
      "cooldown_period": 300,
      "max_recent_responses": 100
    }
  },

  "openai": {
    "prompt": "input_text",
    "system_instruction": {
      "is_dynamic": true,
      "system_prompt": "instructions"
    },
    "api_information": { "model": "gpt-4o-mini" },
    "batch": {
      "is_batch_active": true,
      "batch_size": 20,
      "batch_check_time": 120,
      "combine_batches": false
    }
  },

  "deepseek": {
    "prompt": "input_text",
    "system_instruction": {
      "is_dynamic": true,
      "system_prompt": "instructions"
    },
    "api_information": { "model": "deepseek-chat" },
    "batch": {
      "is_batch_active": true,
      "batch_size": 20,
      "batch_check_time": 120,
      "combine_batches": false
    }
  },

  "deepl": {
    "api_key": "${DEEPL_API_KEY}",
    "target_lang": "lang",   // field name inside input JSON
    "text": "content"        // field with text to translate
  }
}
```

---

## ğŸ–¥ï¸ CLI Usage

The new CLI provides a more intuitive interface for task management:

```bash
# Make sure you're in the project root directory
cd mitrailleuse

# Create a new task
python -m mitrailleuse.main create --user-id user1 --api-name openai --task-name demo

# List available tasks
python -m mitrailleuse.main list --user-id user1

# Get task information
python -m mitrailleuse.main get --task-path /path/to/task

# Execute a task
python -m mitrailleuse.main execute --user-id user1 --task-folder /path/to/task
```

### CLI Features

* Task creation with custom configuration
* Task listing and status monitoring
* Batch job tracking and status updates
* Support for all providers (OpenAI, DeepSeek, DeepL)
* Automatic file flattening and format conversion
* Similarity checking to prevent duplicate responses
* Caching for improved performance

---

## ğŸ—„ï¸ Directory structure (runtime)

```
mitrailleuse/
â”œâ”€ mitrailleuse/
â”‚   â”œâ”€ proto/
â”‚   â”‚   â”œâ”€ mitrailleuse.proto
â”‚   â”‚   â”œâ”€ mitrailleuse_pb2.py
â”‚   â”‚   â””â”€ mitrailleuse_pb2_grpc.py
â”‚   â”œâ”€ infrastructure/
â”‚   â”‚   â”œâ”€ grpc/
â”‚   â”‚   â”‚   â””â”€ server.py
â”‚   â”‚   â””â”€ ...
â”‚   â””â”€ ...
â”œâ”€ tasks/
â”‚   â””â”€ alice/
â”‚       â””â”€ openai_demo_03_05_2025_142530/
â”‚           â”œâ”€ config/config.json
â”‚           â”œâ”€ inputs/
â”‚           â”‚   â”œâ”€ backup/
â”‚           â”‚   â””â”€ ...
â”‚           â”œâ”€ outputs/
â”‚           â”œâ”€ cache/
â”‚           â””â”€ logs/
â”‚               â”œâ”€ app.log
â”‚               â””â”€ batch.log
â””â”€ ...
```

---

## ğŸ›°ï¸ gRPC API reference (proto excerpt)

```proto
service MitrailleuseService {
  rpc CreateTask           (CreateTaskRequest)           returns (TaskEnvelope);
  rpc SendSingle           (SingleRequest)               returns (SingleResponse);
  rpc CreateBatch          (BatchRequest)                returns (BatchJob);
  rpc CheckBatchStatus     (BatchStatusRequest)          returns (BatchJob);
  rpc DownloadBatchResults (BatchResultRequest)          returns (stream BatchLine);
}
```

*Reflection* is enabled: Postman & `grpcurl` can autoâ€‘discover.

---

## ğŸ³ Docker compose

```yaml
services:
  mitrailleuse-grpc:
    build: ./mitrailleuse/grpc
    ports:
      - "50051:50051"
    env_file: .env
    volumes:
      - ./tasks:/app/tasks
```

---

## ğŸ§ª Development & testing

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pytest -q
black . --check
```

Generate updated stubs:

```bash
python -m grpc_tools.protoc -I. \ 
  --python_out=. --grpc_python_out=. mitrailleuse.proto
```

---

## ğŸ“œ License

MIT â€“ see `LICENSE`.

---

## ğŸ—ºï¸ Roadmap

* [ ] DeepSeek batch support when API ships
* [ ] Streaming gRPC endpoint
* [ ] Web dashboard for task monitoring
* [ ] Kubernetes Helm chart
* [ ] Enhanced similarity checking with more algorithms
* [ ] Support for more AI providers

Contributions welcome â€” see `CONTRIBUTING.md`.
